{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "776243dd",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "- Introduction\n",
    "    - The problem of disease subtype discovery from multi-omics data;\n",
    "    - Prostate adenocarcinoma;\n",
    "- Practical Approach:\n",
    "    - Explanation of multi omics dataset utilized;\n",
    "    - Importing of the libraries;\n",
    "    - **Download of the Prostate adenocarcinoma dataset, considering three different omics data sources (mRNA, miRNA and protein expression data). The _TCGA_ code for the dataset is “PRAD”**;\n",
    "    - Explanation of MultiAssayExperiment data structure;\n",
    "    - **Pre-processing of the dataset following the same steps used during lessons. During the filtering by variance, select the first $100$ features having highest variance from each data source**;\n",
    "    - **Download of the disease subtypes (column “Subtype\\_Integrative” is the one containing the iCluster molecular subtypes). Note that not all subtypes are available for the set of samples having all the considered omics data sources, thus you need to retain from the multi-omics dataset only samples having an associated subtype**;\n",
    "    - **Check that patients in multi-omics dataset and subtypes are in the same order**;\n",
    "    - Digression about Similarity Network Fusion;\n",
    "    - **Integration of the data using Similarity Network Fusion with the scaled exponential euclidean distance;**\n",
    "    - **Integration of the similarity matrices from each data source (computed by scaled exponential euclidean distance) using a simple average of the matrices. This can be considered as a trivial multi-omics data integration strategy**;\n",
    "    - Digression about NEMO;\n",
    "    - **Integrate the dataset using another data fusion method called NEMO to obtain an integrated similarity matrix. NEMO implementation is available on github [https://github.com/Shamir-Lab/NEMO]**;\n",
    "    - Digression about PAM;\n",
    "    - **Perform disease subtype discovery (number of clusters equal to the number of disease subtypes foundby iCluster) using PAM algorithm on the following similarity matrices:**\n",
    "        - **Similarity matrices obtained from single data sources (i.e. miRNA, mRNA, proteins) using the usual scaled exponential euclidean distance. Thus, you should obtain three different similarity matrices.To compute the corresponding distance matrix use this code: dist <- 1 - NetPreProc::Prob.norm(W). Prob.norm() function is in the NetPreProc CRAN package (https://cran.r-project.org/web/packages/NetPreProc/index.html). The idea is to normalize the similarity matrix before computing the corresponding distance**;\n",
    "        - **Integrated matrix obtained using the average among matrices.  Use dist <- 1 - NetPreProc::Prob.norm(W) to compute the distance matrix**; \n",
    "        - **Integrated matrix obtained using Similarity Network Fusion**;\n",
    "        - **Integrated matrix obtained using NEMO. Use dist <- 1 - NetPreProc::Prob.norm(W)to compute the distance matrix.**\n",
    "    - **NEMO provides the possibility of performing clustering using another approach called Spectral Clustering. Use the function nemo.clustering() to test this approach.**\n",
    "    - Analysis based on iCluster disease subtypes;\n",
    "    - **Comparation of the clusterings obtained by each considered approach w.r.t. the iCluster disease subtypes. Make tables and plots to show the results and discuss them.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f84324c",
   "metadata": {},
   "source": [
    "## The problem of disease subtype discovery from multi-omics data\n",
    "Remarkable advancements in technology have facilitated the generation of diverse genome-wide high-throughput\n",
    "biological data types, collectively referred to as **omics**. Omic is a suffix used to refer to different fields of study that involve comprehensive analysis of a specific biological component or aspect. It typically denotes a multidimensional approach to studying biological systems on a large scale, encompassing various molecular components, such as genes (**genomics**), proteins (**proteomics**), metabolites (**metabolomics**), and more. The omic sciences aim to understand the complex interactions and functions of these components to gain insights into biological processes. By utilizing the omic approach, researchers seek a comprehensive understanding of biological systems at a molecular level, exploring the intricate networks and relationships that contribute to an organism's structure, function, and behavior.\n",
    "\n",
    "The wealth of these omic profiles gathered from large cohorts in recent years presents a unique opportunity to gain a deeper understanding of human diseases. These profiles can serve as valuable resources for characterizing diseases more comprehensively, thus facilitating the development of personalized treatment strategies tailored to individual patients.\n",
    "\n",
    "In the field of oncology, the analysis of extensive datasets has led to the identification of novel cancer subtypes, revolutionizing treatment decision-making. \n",
    "However, typically, the attained results are based on the analysis of a single omic rather than being derived from a comprehensive analysis of multiple data sources. Since the molecular complexity of a tumor manifests itself at the omics levels, genomic profiling at these multiple levels allows a better integrated characterization of tumor etiology.\n",
    "\n",
    "Identifying tumor subtypes by simultaneously analyzing **multi-omic data** is a relatively new problem. In fact, since initiatives like **The Cancer Genome Atlas** (henceforth referred to as **TCGA**) have made multi-omic cohort data available, there has been a pressing need for improved and advanced methodologies that enable the integrated analysis of these datasets.\n",
    "The simplest way utilized to combine biological data was to concatenate normalized measurements from various biological domains for each sample. Concatenation further dilutes the already low signal-to-noise ratio in each data type. To avoid this, a common strategy was to analyze each data type independently before combining data. In fact, the most used approach to subtype discovery across multiple types in the past years was to separately cluster each type and then to manually integrate the result. However, such independent analyses often led to inconsistent conclusions that were hard to integrate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c007fdb",
   "metadata": {},
   "source": [
    "### Multi-omics clustering methods\n",
    "There are several approaches to multi-omics clustering. The simplest one, called **early integration** (also named **concatenation-based**), is applied on the input data in an early stage and it concatenates all omic matrices into one matrix and applies single-omic clustering on the resulting one. This type of method probabilistically models the distribution of numeric, count and discrete features. The evident advantage of early methods relies on their ability to uncover the individual information characterizing each of the different sources as well as the hidden relationships between them. Another considerable advantage is brought by the fact that early methods solve the integration problem in the first stage, so that any unimodal analysis process may be subsequentially applied. Nevertheless, these methods suffer from the increasing of the dimensionality of the data. They also ignore the different distributions of values in different omics.\n",
    "\n",
    "Another approach, called **late integration** method  (also named **model-based**), clusters each omic separately, and then integrates in a late phase the clustering results, for example using **consensus clustering**. This approach has the flaw of ignoring interactions that are weak but consistent across omics, discarding in this way an important piece of information. These approaches along with the early integration ones are classified as **model-agnostic**. They are named **agnostic** because they are independent from the specific algorithm applied in the preceding unimodal analysis, which can be therefore tailored to the processed type.\n",
    "\n",
    "Finally, an ulterior integrative clustering approach, which accounts for all omics, is the one called **middle integration**. It allows joint inference from multi-omic data and generates a single integrated cluster assignment through simultaneously capturing patterns of genomic alterations that are consistent across multiple data types, specific to individual data types or weak yet consistent across datasets that would emerge only as a result of combining levels of evidence.\n",
    "However, this data-integration method needs to overcome at least three **computational challenges**: the small number of samples compared to the large number of measurements, the differences in scale, collection bias and noise in each data set, and the complementary nature of the information provided by different types of data.\n",
    "**dimension reduction** is a key to the feasibility and performance of these integrative clustering approaches. Methods that rely on pairwise correlation matrices are, in fact, computationally prohibitive with today’s high-resolution arrays.\n",
    "Therefore, because of the high number of features and because of the complexity of dimension reduction algorithms, feature selection is required. Similarity based methods handle these shortcomings by working with inter-patient-similarities. These methods have improved runtime tand are less reliant on feature selection.\n",
    "\n",
    "All middle integration methods for multi-omics clustering developed within the bioinformatics community assume full datasets, i.e., data from all omics were measured for each patient. However, in real experimental settings, often, for some patients, only a subset of the omics were measured. These datasets are called **partial datasets**. This phenomenon is already prevalent in existing multi-omic datasets and will increase as cohorts grow. Being able to analyze partial data is of paramount importance due to the high cost of experiments and the unequal cost for acquiring data for different omics. Naive solutions like using only those patients with all omics measured or **imputation** (the assignment of a value to something by inference from the value of the products or processes to which it contributes) have obvious disadvantage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c893dd7",
   "metadata": {},
   "source": [
    "## Prostate adenocarcinoma\n",
    "**Prostate cancer** is a cancer type that affects the prostate gland and it is the second most common cancer types among men and, in general, ranking fourth in frequency worldwide. A combination of genetic and demographic factors like age, family history, genetic susceptibilityt and race contribute to its high incidence. \n",
    "\n",
    "The clinical behavior of localized prostate cancer can vary widely, with some individuals having aggressive cancer that can spread and cause death, while others have indolent cancer that can be treated or observed safely.\n",
    "\n",
    "To better predict the likelihood of progression and tailor treatment accordingly, **risk stratification systems** have been developed that take into account various clinical and pathological parameters. **Risk stratification** is the process of categorizing individuals or entities into different **risk levels** based on certain characteristics or factors in order to predict the likelihood of an event or outcome occurring and, therefore, risk stratification systems are tools employed to assign individuals or entities to specific risk categories. These systems aim to identify individuals at higher risk for aggressive disease and guide treatment decisions, taking into account factors such as **prostate-specific antigen** (**PSA**) levels, **Gleason score** (a measure of cancer aggressiveness based on biopsy samples), clinical stage, and other factors.\n",
    "\n",
    "Despite these systems' usefulness, it is fundamental to keep in mind that they are not perfect, and there is still a need for improved risk stratification. This is where molecular features come into play. Molecular and genetic profiles are increasingly being used to subtype various cancer types and guide targeted treatment interventions.\n",
    "\n",
    "Recent research has identified several genomic alterations as key features of primary prostate cancer, including **mutations** (changes in the DNA sequence, where one or more nucleotides are altered), **DNA copy-number changes** (changes in the number of copies of a specific DNA sequence or gene in a cell's genome), **rearrangements** (changes in the structure or arrangement of larger segments of DNA, such as genes or whole chromosomes), and **gene fusions** (the joining or fusion of two separate genes, resulting in the formation of a hybrid gene). The most common genomic alteration in prostate cancer is the fusion of **androgen-regulated promoters** (regions of DNA that control the expression of genes in response to androgen hormones, such as testosterone) with members of the **ETS family** of transcription factors such as ERG. The ETS family is a group of genes that encode proteins involved in regulating gene expression. These transcription factors control the activity of various genes, influencing important cellular processes like growth, differentiation, and development.\n",
    "\n",
    "However, individuals with fusion-bearing tumors do not appear to have a different prognosis following treatment than those without.\n",
    "\n",
    "Prostate cancers also have varying degrees of DNA copy-number alteration, with indolent and low-Gleason tumors having fewer alterations, while more aggressive tumors have a higher burden of copy-number alteration throughout the genome.\n",
    "\n",
    "Further research on the molecular basis of prostate cancer and risk stratification could help identify those at higher risk of developing aggressive disease, leading to better treatment options and outcomes for patients. Therefore, there is a need to continue studying the molecular characteristics of prostate cancer to develop better risk stratification and treatment strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daf3724",
   "metadata": {},
   "source": [
    "The goal of this project is to discover disease subtypes in the prostate adenocarcinoma dataset from the Cancer Genome Atlas utilizing clustering techniques and to compare the results with the one from TCGA, which used **iCluster**, an integrative clustering model on multi-omics data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc3b1a1",
   "metadata": {},
   "source": [
    "First of all, we need to install all the packages needed for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a062aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (!require(\"BiocManager\", quietly = TRUE))\n",
    "#    install.packages(\"BiocManager\")\n",
    "\n",
    "# BiocManager::install(\"curatedTCGAData\");\n",
    "# BiocManager::install(\"TCGAutils\");\n",
    "# BiocManager::install(\"TCGAbiolinks\");\n",
    "\n",
    "# install.packages(\"SNFtool\");\n",
    "# install.packages(\"caret\");\n",
    "# install.packages(\"cluster\");\n",
    "# install.packages(\"mclustcomp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2450864",
   "metadata": {},
   "source": [
    "Now we can load the packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f533dae0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "library(\"curatedTCGAData\");\n",
    "library(\"TCGAbiolinks\");\n",
    "library(\"TCGAutils\");\n",
    "library(\"SNFtool\");\n",
    "library(\"caret\");\n",
    "library(\"cluster\"); #pam\n",
    "library(\"mclustcomp\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e598a550",
   "metadata": {},
   "source": [
    "As above-mentioned, we will download **multi-omics** data from patients having prostate cancer. A multi-omics dataset is a dataset comprising multiple different biological data sources where each source represents a different data modality capturing the state of a specific biological layer in the cells.\n",
    "\n",
    "The advent of the so-called “high-throughput technologies” enables the evaluation of:\n",
    "- **Genome**: the complete genetic information of an organism (i.e. the sequence of nucleotides in the DNA);\n",
    "- **Transcriptome**: set of all RNA transcripts (used also for all mRNA);\n",
    "- **Proteome**: entire set of proteins etc.\n",
    "\n",
    "in cell, tissue, or organism at a certain time. All omics data are high-dimensional and characterized by **small-n large-p** (i.e. few samples and a large number of features), which easily leads to the **curse of dimensionality** in machine learning applications. In machine learning, the curse of dimensionality is the deterioration of algorithm performance caused by the exponential growth of data volume as the number of input features or dimensions increases. As the dimensionality of the data increases, the available data becomes increasingly sparse in the high-dimensional space, resulting in difficulties in accurately representing and analyzing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603bb72d",
   "metadata": {},
   "source": [
    "We download a prostate cancer multi-omics dataset from The Cancer Genome Atlas (TCGA) program. In particular, we exploit the package “curatedTCGAData” to download the following data views:\n",
    "- **mRNA data**;\n",
    "- **miRNA data**;\n",
    "- **protein data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7f6ef9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download prostate cancer multi-omics dataset.\n",
    "# Note that RPPA stands for Reverse-phase protein array and it is the technology used to obtain proteomic data.\n",
    "assays <- c(\"miRNASeqGene\", \"RNASeq2Gene\", \"RPPAArray\");\n",
    "mo <- curatedTCGAData(diseaseCode = \"PRAD\", \n",
    "                        assays = assays, \n",
    "                        version = \"2.0.1\", dry.run = FALSE);\n",
    "\n",
    "# This command print a summary of the MultiAssayExperiemnt object.\n",
    "mo;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75080dd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This subset does not change the content of the variable \"mo\" if using the version 4.2.0 of R.\n",
    "mo <- mo[, , paste0(\"PRAD\", \"_\", assays, \"-20160128\")];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95115c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the actual number of entries in the sampleMap. It can be noticed that the number of entries in the\n",
    "# sampleMap DataFrame is still the same after the subsetting (1449 rows and 3 columns).\n",
    "sampleMap(mo);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187b6d53",
   "metadata": {},
   "source": [
    "As we can see, we obtain a MultiAssayExperiment object, which, in its essence, is a data structure designed to store and coordinately analyze multi-omics experiments. The three main components of this data structure are:\n",
    "- **colData**: it contains a dataframe having for each sample the corresponding phenotipic characteristics (in our case mainly clinical data) - access colData()\n",
    "- **ExperimentList**: a list with the considered experiments (i.e. data modalities acquired with a specific technology). Element of the list are usually matrices or dataframes - access experiments()\n",
    "- **sampleMap**: it is a map that connects all the considered elements.- access sampleMap()\n",
    "\n",
    "Moreover, a function is provided to build MultiAssayExperiment objects for your own data and also subsetting operations for coordinated data selection among views."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57c7476",
   "metadata": {},
   "source": [
    "To work with data coming from TCGA, it is important to understand the structure of the **barcode** associated to each sample. A TCGA barcode is composed of a collection of identifiers. Each sample/patient is identified by one of this barcode with a specific structure: in pratice, the first 12 characters of the barcode identify a specific individual, while the other parts give us indications about the type of sample (i.e. primary, metastatic, solid, blood derived, etc), the type of genomic material extracted (i.e. DNA, RNA) and other information related to technical replicates (i.e. repeated measurements from the same sample).  Each specifically identifies a TCGA data element.\n",
    "\n",
    "We use the barcode to retain only Primary Solid Tumors to have a more homogeneous group of samples and to check for the presence of technical replicates in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8c8756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We extract the samples knowing that the type of tumor is indicated in the barcode. In TCGA “Primary Solid Tumors”\n",
    "# are identified by the code “01” in the sample part of the barcode.\n",
    "# Consider only primary solid tumors because primary tumors originate in a specific organ or tissue and are\n",
    "# generally more consistent in terms of location, size, and characteristics compared to metastatic tumors\n",
    "# (secondary tumors that spread from the primary site). Focusing on primary tumors helps maintain statistical\n",
    "# validity by comparing similar types of tumors, reducing variability and confounding factors that may arise\n",
    "# from studying different metastatic sites.\n",
    "primary <- TCGAutils::TCGAsampleSelect(colnames(mo), c(\"01\"));\n",
    "primary;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f91c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The execution of the precedent cell raises a warnin due to the fact that the barcode associated with\n",
    "# the RPPAArray is composed by 27 characters while the others are composed by 28 characters.\n",
    "print(colnames(mo)[1]);\n",
    "print(colnames(mo)[2]);\n",
    "print(colnames(mo)[3]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c74d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo <- mo[, primary, ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c46596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the actual number of entries in the sampleMap (1343 rows and 3 columns).\n",
    "sampleMap(mo);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c20894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for replicates (anyReplicated() checks the so called biological or primary unit in the sampleMap of the\n",
    "# MultiAssayExperiment object, that corresponds to the first 12 characters of the barcodes for TCGA data). In fact,\n",
    "# If two samples have the same 12 characters in their barcodes, then they come from the same patient and can be\n",
    "# identified as technical replicated (since we already filtered for the same sample type). The outcome (\"FALSE\")\n",
    "# indicates that there were no replicates.\n",
    "check_rep <- anyReplicated(mo);\n",
    "print(check_rep);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979431df",
   "metadata": {},
   "source": [
    "Then, other additional pre-processing steps are performed:\n",
    "\n",
    "- Remove **FFPE** (**formalin-fixed, paraffin-embedded**) samples. Broadly speaking, after a biopsy is performed we need to store and preserve the sample. Two major tissue preparation methods are generally used: (1) FFPE, (2) freezing the sample. DNA and RNA molecules are preserved better if the tissue is frozen, thus we will remove samples preserved using FFPE technique;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4377f528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The information regarding if the sample is FFPE is stored in the clinical data, which are accessible using\n",
    "# colData(). \n",
    "no_ffpe <- which(as.data.frame(colData(mo))$patient.samples.sample.is_ffpe == \"no\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a503c7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mo <- mo[, no_ffpe, ];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e409735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the actual number of entries in the sampleMap (1343 rows and 3 columns);\n",
    "sampleMap(mo);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcee34d",
   "metadata": {},
   "source": [
    "- Restrict samples to the ones having all the considered omics and extract the set of omics (one matrix for each omic) in a list;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59128ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersectColumns() is a wrapper for complete.cases to return a MultiAssayExperiment with only those biological\n",
    "# units that have measurements across all experiments. We will obtain samples having all the considered omics\n",
    "# (1044 rows and 3 columns).\n",
    "complete <- intersectColumns(mo);\n",
    "sampleMap(complete);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1681e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract assays in list of matrices. To access an assay it is possible to use complete$assaysname\n",
    "complete <- assays(complete);\n",
    "complete;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ec6a65",
   "metadata": {},
   "source": [
    "- Transpose each matrix to have samples in the rows and features in columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30383a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain matrices samples x features:\n",
    "complete <- lapply(complete, FUN=t);\n",
    "complete;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d0407a",
   "metadata": {},
   "source": [
    "- Remove features having missing values (i.e. NA). In this case it is easier to remove features instead of performing imputation, since only few features in the proteomics data have missing values;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f9c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features having NAs (present only in proteomics data).\n",
    "# In details, \"is.na(complete[[3]])\" checks for missing values (NA) in the third matrix.\n",
    "# \"colSums(is.na(complete[[3]]))\" calculates the column-wise sums of missing values. It returns a numeric vector\n",
    "# with the same number of elements as the number of columns in complete[[3]]. Each element represents the count of\n",
    "# missing values in the corresponding column.\n",
    "# \"colSums(is.na(complete[[3]])) == 0\" creates a logical vector indicating which columns have no missing values.\n",
    "# It returns TRUE for columns with no missing values and FALSE otherwise.\n",
    "# \"complete[[3]][, colSums(is.na(complete[[3]])) == 0]\" selects columns from the proteomics matrix where the\n",
    "# corresponding column in colSums(is.na(complete[[3]])) == 0 is TRUE. In other words, it keeps only the columns\n",
    "# that have no missing values.\n",
    "complete[[3]] <- complete[[3]][, colSums(is.na(complete[[3]])) == 0];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1c23ab",
   "metadata": {},
   "source": [
    "- Select features having more variance across samples. Here we make a strong assumption: features that have more variance across samples bring more information and are the more relevant ones. This feature selection strategy is fast and commonly used in literature, however it as some drawbacks: (1) it is univariate, thus does not considers interactions among features and (2) it is not able to remove redundant variables. Moreover, we need to identify a threshold for feature selection (top 100 features) but it is always an arbitrary choice;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7cd30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features with near zero variance and retain top 100 features having higher variance.\n",
    "# \"nearZeroVar()\", from the caret package, is used to identify variables with near-zero variance, which means they\n",
    "# have very little or no variation in their values. The resulting indices are stored in the \"idx\" variable.\n",
    "# Then, if the length of the \"idx\" variable is not zero, the expression \"complete[[i]][, -idx]\"\" is used to subset\n",
    "# the i-th element of complete and remove the columns specified by the idx variable. Then, it modifies the i-th\n",
    "# element within the \"complete\" list by removing the columns identified by \"idx\" from that element.\n",
    "# The modified element is then assigned back to the i-th position in the \"complete\" list.\n",
    "nf <- 100;\n",
    "for(i in 1:length(complete)){\n",
    "    \n",
    "    idx <- caret::nearZeroVar(complete[[i]]);\n",
    "    message(paste(\"Removed \", length(idx), \"features from\", names(complete)[i]));\n",
    "    if(length(idx) != 0){\n",
    "        complete[[i]] <- complete[[i]][, -idx];\n",
    "    }\n",
    "\n",
    "    if(ncol(complete[[i]]) <= nf) next\n",
    "    \n",
    "    vars <- apply(complete[[i]], 2, var);\n",
    "    idx <- sort(vars, index.return=TRUE, decreasing = TRUE)$ix;\n",
    "    \n",
    "    complete[[i]] <- complete[[i]][, idx[1:nf]];\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd298a8",
   "metadata": {},
   "source": [
    "- Standardize features using z-score;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df8d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform features standardization using z-score. Z-score normalization is a statistical technique used to\n",
    "# transform a dataset so that it has a mean of zero and a standard deviation of one.\n",
    "# This process allows us to compare and analyze data that originally had different scales or units.\n",
    "zscore <- function(data){\n",
    "    \n",
    "    zscore_vec <- function(x) { return ((x - mean(x)) / sd(x))};\n",
    "    data <- apply(data, 2, zscore_vec);\n",
    "    \n",
    "    \n",
    "    return(data);\n",
    "}\n",
    "\n",
    "complete <- lapply(complete, zscore);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76da8f49",
   "metadata": {},
   "source": [
    "- Clean barcodes to retain only the first part specific for each individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean barcodes retaining only \"Project-TSS-Participant\", that is, the unique identifier for each patient. \n",
    "# We substitute the names of the rows with the substring composed by their first 12 characters. \n",
    "for(v in 1:length(complete)){\n",
    "    rownames(complete[[v]]) <- substr(rownames(complete[[v]]), 1, 12);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b74df9a",
   "metadata": {},
   "source": [
    "The classification of a sample to a specific disease subtype helps to predict patients’ prognosis and it has an impact also on the definition of the therapy. Many different tests to define the disease subtype of a prostate cancer patient are available, which consider different subset of genes for the definition of the subtypes. TCGA provides the subtypes defined using the PAM50 model, which considers the expression of a minimal set of 50 genes. We will try to see if the clusters we compute are similar to the PAM50 disease subtypes provided by TCGA for prostate cancer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4ac28b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Download disease subtypes from TCGAbiolinks:\n",
    "subtypes <- as.data.frame(TCGAbiolinks::PanCancerAtlas_subtypes());\n",
    "subtypes <- subtypes[subtypes$cancer.type == \"PRAD\", ];\n",
    "subtypes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36a8a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the rows with a Nan value in the Subtype_Integrative column\n",
    "subtypes <- subtypes[!is.na(subtypes$Subtype_Integrative),];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6e7cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only primary solid tumors and select samples in common with omics data (in the same order):\n",
    "subtypes <- subtypes[TCGAutils::TCGAsampleSelect(subtypes$pan.samplesID, \"01\"), ];\n",
    "sub_select <- substr(subtypes$pan.samplesID,1,12) %in% rownames(complete[[1]]);\n",
    "subtypes <- subtypes[sub_select, ];\n",
    "rownames(subtypes) <- substr(subtypes$pan.samplesID, 1, 12);\n",
    "subtypes <- subtypes[rownames(complete[[1]]),];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc23a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of samples for each subtype:\n",
    "table(subtypes$Subtype_Selected);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b5d549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarity matrix for each data source using the scaled\n",
    "# exponential euclidean distance:\n",
    "W_list <- list();\n",
    "for(i in 1:length(complete)){\n",
    "    Dist <- (dist2(as.matrix(complete[[i]]), as.matrix(complete[[i]])))^(1/2);\n",
    "    W_list[[i]] <- affinityMatrix(Dist);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b074bf",
   "metadata": {},
   "source": [
    "As already said, Similarity Network Fusion is a similarity method that works with inter-patient-similarities. SNF builds a similarity network of patients per omic and iteratively updates these networks to increase their similarity until they converge to a single network, which is then partitioned using spectral clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8abd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integration of multi-omics data using Similarity Network Fusion:\n",
    "# t is the number of iterations and K is the number of neighbours to \n",
    "# consider to compute the local similarity matrix:\n",
    "W_int <- SNF(W_list, K=20, t=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14683206",
   "metadata": {},
   "source": [
    "**NEMO** (**NE**ighborhood based **M**ulti-**O**mics clustering) is a simple algorithm for multi-omics clustering. NEMO does not require iterative optimization and is faster than prior art.\n",
    "NEMO is inspired and built on prior similarity-based multi-omics clustering methods such as SNF.\n",
    "NEMO works in three phases. First, an inter-patient similarity matrix is built for each omic. Next, the matrices of different omics are integrated into one matrix. Finally, that network is clustered."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
